{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(\"This is the first sentence written by Dr. John.\")\n",
    "# for token in doc:\n",
    "#   print(token)\n",
    "# print(type(nlp))\n",
    "# print(type(doc))\n",
    "# print(type(doc[0]))\n",
    "# print(type(doc[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "first_token = doc[0]\n",
    "print(first_token.is_alpha)\n",
    "fourth_token = doc[3]\n",
    "print(fourth_token.like_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gim', 'me', 'two', 'bucks']\n"
     ]
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp.tokenizer.add_special_case(\"Gimme\", [\n",
    "  {\n",
    "    ORTH: \"Gim\"\n",
    "  },\n",
    "  {\n",
    "    ORTH: \"me\"\n",
    "  }\n",
    "])\n",
    "\n",
    "doc = nlp(\"Gimme two bucks\")\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencizer']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Workplace\\Learning\\Courses\\NLP Tutorial For Beginners In Python\\code\\8. spacy_tokenization.ipynb Cell 5'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Workplace/Learning/Courses/NLP%20Tutorial%20For%20Beginners%20In%20Python/code/8.%20spacy_tokenization.ipynb#ch0000004?line=1'>2</a>\u001b[0m nlp\u001b[39m.\u001b[39madd_pipe(\u001b[39m'\u001b[39m\u001b[39msentencizer\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Workplace/Learning/Courses/NLP%20Tutorial%20For%20Beginners%20In%20Python/code/8.%20spacy_tokenization.ipynb#ch0000004?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(nlp\u001b[39m.\u001b[39mpipe_names)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Workplace/Learning/Courses/NLP%20Tutorial%20For%20Beginners%20In%20Python/code/8.%20spacy_tokenization.ipynb#ch0000004?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39msents:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Workplace/Learning/Courses/NLP%20Tutorial%20For%20Beginners%20In%20Python/code/8.%20spacy_tokenization.ipynb#ch0000004?line=4'>5</a>\u001b[0m   \u001b[39mprint\u001b[39m(token)\n",
      "File \u001b[1;32mD:\\Softwares\\Python\\lib\\site-packages\\spacy\\tokens\\doc.pyx:875\u001b[0m, in \u001b[0;36msents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
     ]
    }
   ],
   "source": [
    "# Adding sentencizer component to language model pipeline\n",
    "nlp.add_pipe('sentencizer')\n",
    "print(nlp.pipe_names)\n",
    "for token in doc.sents:\n",
    "  print(token)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23226dcb379d0ed0866266b24bdca6ba08c94e9c5b850a146778e390a9c8ac73"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
